# 浑元世界1.0：从文字或像素生成沉浸式、可探索和交互式的3D世界

**论文ID**：2507.21809
**英文标题**：HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D   Worlds from Words or Pixels
**中文标题**：浑元世界1.0：从文字或像素生成沉浸式、可探索和交互式的3D世界
**论文地址**：https://arxiv.org/abs/2507.21809

**作者团队**：HunyuanWorld Team, Zhenwei Wang, Yuhao Liu, Junta Wu, Zixiao Gu, Haoyuan Wang, Xuhui Zuo, Tianyu Huang, Wenhuan Li, Sheng Zhang, Yihang Lian, Yulin Tsai, Lifu Wang, Sicong Liu, Puhua Jiang, Xianghui Yang, Dongyuan Guo, Yixuan Tang, Xinyue Mao, Jiaao Yu, Junlin Yu, Jihong Zhang, Meng Chen, Liang Dong, Yiwen Jia, Chao Zhang, Yonghao Tan, Hao Zhang, Zheng Ye, Peng He, Runzhou Wu, Minghui Chen, Zhan Li, Wangchen Qin, Lei Wang, Yifu Sun, Lin Niu, Xiang Yuan, Xiaofeng Yang, Yingping He, Jie Xiao, Yangyu Tao, Jianchen Zhu, Jinbao Xue, Kai Liu, Chongqing Zhao, Xinming Wu, Tian Liu, Peng Chen, Di Wang, Yuhong Liu, Linus, Jie Jiang, Tengfei Wang, Chunchao Guo
**发表日期**：2025-07-29

**英文摘要**：
Creating immersive and playable 3D worlds from texts or images remains a
fundamental challenge in computer vision and graphics. Existing world
generation approaches typically fall into two categories: video-based methods
that offer rich diversity but lack 3D consistency and rendering efficiency, and
3D-based methods that provide geometric consistency but struggle with limited
training data and memory-inefficient representations. To address these
limitations, we present HunyuanWorld 1.0, a novel framework that combines the
best of both worlds for generating immersive, explorable, and interactive 3D
scenes from text and image conditions. Our approach features three key
advantages: 1) 360{\deg} immersive experiences via panoramic world proxies; 2)
mesh export capabilities for seamless compatibility with existing computer
graphics pipelines; 3) disentangled object representations for augmented
interactivity. The core of our framework is a semantically layered 3D mesh
representation that leverages panoramic images as 360{\deg} world proxies for
semantic-aware world decomposition and reconstruction, enabling the generation
of diverse 3D worlds. Extensive experiments demonstrate that our method
achieves state-of-the-art performance in generating coherent, explorable, and
interactive 3D worlds while enabling versatile applications in virtual reality,
physical simulation, game development, and interactive content creation.

**中文摘要**：
从文本或图像创建沉浸式和可玩的3D世界仍然是计算机视觉和图形学中的一个基本挑战。现有的世界生成方法通常分为两类：基于视频的方法提供了丰富的多样性，但缺乏3D一致性和渲染效率；而基于3D的方法提供了几何一致性，但面临着训练数据有限和内存效率低下的表示方式的挑战。为了解决这些局限性，我们提出了浑元世界1.0，这是一个新颖的框架，结合了两种方法的优势，从文本和图像条件生成沉浸式、可探索和交互式的3D场景。我们的方法具有三个关键优势：1) 通过全景世界代理提供360度沉浸式体验；2) 网格导出功能，与现有计算机图形管线无缝兼容；3) 解耦的对象表示，增强交互性。我们框架的核心是一种语义分层的3D网格表示，它利用全景图像作为360度世界代理，进行语义感知的世界分解和重建，从而能够生成多样化的3D世界。大量实验表明，我们的方法在生成连贯、可探索和交互式的3D世界方面取得了最先进的性能，同时在虚拟现实、物理模拟、游戏开发和交互式内容创作等应用中展现了广泛的用途。

**GitHub仓库**：https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0
**项目页面**：https://3d-models.hunyuan.tencent.com/world/
**模型功能**：从文本或图像生成沉浸式、可探索和交互式3D世界，支持全景体验与图形管线兼容。

**分析时间**：2025-08-04T19:21:02.765710
