# 面向视觉运动智能体可泛化空间智能的可扩展多任务强化学习

**论文ID**：2507.23698
**英文标题**：Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents
**中文标题**：面向视觉运动智能体可泛化空间智能的可扩展多任务强化学习
**论文地址**：https://arxiv.org/abs/2507.23698

**作者团队**：Shaofei Cai, Zhancun Mu, Haiwen Xia, Bowei Zhang, Anji Liu, Yitao Liang
**发表日期**：2025-07-31

**英文摘要**：
While Reinforcement Learning (RL) has achieved remarkable success in language
modeling, its triumph hasn't yet fully translated to visuomotor agents. A
primary challenge in RL models is their tendency to overfit specific tasks or
environments, thereby hindering the acquisition of generalizable behaviors
across diverse settings. This paper provides a preliminary answer to this
challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can
achieve zero-shot generalization to unseen worlds. Specifically, we explore
RL's potential to enhance generalizable spatial reasoning and interaction
capabilities in 3D worlds. To address challenges in multi-task RL
representation, we analyze and establish cross-view goal specification as a
unified multi-task goal space for visuomotor policies. Furthermore, to overcome
the significant bottleneck of manual task design, we propose automated task
synthesis within the highly customizable Minecraft environment for large-scale
multi-task RL training, and we construct an efficient distributed RL framework
to support this. Experimental results show RL significantly boosts interaction
success rates by 4times and enables zero-shot generalization of spatial
reasoning across diverse environments, including real-world settings. Our
findings underscore the immense potential of RL training in 3D simulated
environments, especially those amenable to large-scale task generation, for
significantly advancing visuomotor agents' spatial reasoning.

**中文摘要**：
虽然强化学习(RL)在语言建模方面取得了显著成功，但其成就尚未完全转化为视觉运动智能体。RL模型的一个主要挑战是它们倾向于过度拟合特定任务或环境，从而阻碍了在各种环境中获取可泛化的行为。本文通过证明在Minecraft中经过RL微调的视觉运动智能体能够实现对未见世界的零样本泛化，为这一挑战提供了初步答案。具体而言，我们探索了RL增强3D世界中可泛化空间推理和交互能力的潜力。为了解决多任务RL表示中的挑战，我们分析和建立了跨视图目标规范作为视觉运动策略的统一多任务目标空间。此外，为了克服手动任务设计的重要瓶颈，我们在高度可定制的Minecraft环境中提出了自动化任务合成，用于大规模多任务RL训练，并构建了一个高效的分布式RL框架来支持这一点。实验结果表明，RL显著将交互成功率提高了4倍，并实现了空间推理在包括现实世界环境在内的各种环境中的零样本泛化。我们的研究结果强调了在3D模拟环境中进行RL训练的巨大潜力，特别是那些适合大规模任务生成的环境，对于显著提升视觉运动智能体的空间推理能力。

**GitHub仓库**：https://github.com/CraftJarvis/ROCKET-3
**项目页面**：暂无
**模型功能**：通过可扩展多任务强化学习提升视觉运动智能体在3D环境中的空间推理能力和零样本泛化性能。

**技术特点**：提出跨视图目标规范作为统一多任务目标空间，解决了多任务RL表示挑战；实现Minecraft环境中的自动化任务合成，克服手动任务设计瓶颈；构建高效分布式RL框架，支持大规模训练并实现零样本泛化到未见世界和现实环境。

**应用场景**：游戏AI开发，为开放世界游戏创建适应多环境的智能体；机器人导航与交互，训练机器人在复杂3D环境中进行空间推理；虚拟现实与增强现实应用，开发适应虚拟空间变化的交互智能体。

**分析时间**：2025-08-04T17:49:02.690577