# 流等价循环神经网络

**论文ID**：2507.14793
**英文标题**：Flow Equivariant Recurrent Neural Networks
**中文标题**：流等价循环神经网络
**论文地址**：https://arxiv.org/abs/2507.14793

**作者团队**：T. Anderson Keller
**发表日期**：2025-07-20

**英文摘要**：
Data arrives at our senses as a continuous stream, smoothly transforming from
one instant to the next. These smooth transformations can be viewed as
continuous symmetries of the environment that we inhabit, defining equivalence
relations between stimuli over time. In machine learning, neural network
architectures that respect symmetries of their data are called equivariant and
have provable benefits in terms of generalization ability and sample
efficiency. To date, however, equivariance has been considered only for static
transformations and feed-forward networks, limiting its applicability to
sequence models, such as recurrent neural networks (RNNs), and corresponding
time-parameterized sequence transformations. In this work, we extend
equivariant network theory to this regime of `flows' -- one-parameter Lie
subgroups capturing natural transformations over time, such as visual motion.
We begin by showing that standard RNNs are generally not flow equivariant:
their hidden states fail to transform in a geometrically structured manner for
moving stimuli. We then show how flow equivariance can be introduced, and
demonstrate that these models significantly outperform their non-equivariant
counterparts in terms of training speed, length generalization, and velocity
generalization, on both next step prediction and sequence classification. We
present this work as a first step towards building sequence models that respect
the time-parameterized symmetries which govern the world around us.

**中文摘要**：
数据以连续流的形式到达我们的感官，从一个瞬间平滑地转变为下一个瞬间。这些平滑变换可以被视为我们所居住环境的连续对称性，定义了随时间变化的刺激之间的等价关系。在机器学习中，尊重其数据对称性的神经网络架构被称为等变的，并且在泛化能力和样本效率方面具有可证明的优势。然而，迄今为止，等变性仅被考虑用于静态变换和前馈网络，这限制了其在序列模型（如循环神经网络（RNN））以及相应的时间参数化序列变换中的应用。在这项工作中，我们将等变网络理论扩展到'流'这一领域——捕获随时间自然变换的单参数李子群，例如视觉运动。我们首先证明标准的RNN通常不是流等变的：对于移动的刺激，它们的隐藏状态未能以几何结构化的方式进行变换。然后我们展示了如何引入流等变性，并证明这些模型在训练速度、长度泛化和速度泛化方面显著优于其非等变的对应模型，无论是在下一步预测还是序列分类任务中。我们提出这项工作作为构建尊重支配我们周围世界的时间参数化对称性的序列模型的第一步。

**GitHub仓库**：暂无
**项目页面**：暂无
**模型功能**：流等价循环神经网络，处理时间连续变换的序列数据，提升训练速度和泛化能力。

**技术特点**：首次将等变网络理论扩展到处理时间参数化"流"变换的领域，设计了能使隐藏状态以几何结构化方式变换的RNN架构，在训练速度、长度泛化和速度泛化方面显著优于传统RNN模型。

**应用场景**：视觉运动分析和预测，如视频中的物体跟踪和运动预测；机器人感知和控制，处理连续传感器数据并做出相应决策；时间序列预测任务，特别是涉及连续变换的数据，如气象预测和金融市场分析。

**分析时间**：2025-08-04T17:50:16.959011