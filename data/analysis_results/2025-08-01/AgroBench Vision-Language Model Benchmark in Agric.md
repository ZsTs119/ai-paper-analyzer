# AgroBench: Vision-Language Model Benchmark in Agriculture

**论文ID**：2507.20519
**英文标题**：AgroBench: Vision-Language Model Benchmark in Agriculture
**中文标题**：AgroBench: Vision-Language Model Benchmark in Agriculture
**论文地址**：https://arxiv.org/abs/2507.20519

**作者团队**：Risa Shinoda, Nakamasa Inoue, Hirokatsu Kataoka, Masaki Onishi, Yoshitaka Ushiku
**发表日期**：2025-07-28

**英文摘要**：
Precise automated understanding of agricultural tasks such as disease
identification is essential for sustainable crop production. Recent advances in
vision-language models (VLMs) are expected to further expand the range of
agricultural tasks by facilitating human-model interaction through easy,
text-based communication. Here, we introduce AgroBench (Agronomist AI
Benchmark), a benchmark for evaluating VLM models across seven agricultural
topics, covering key areas in agricultural engineering and relevant to
real-world farming. Unlike recent agricultural VLM benchmarks, AgroBench is
annotated by expert agronomists. Our AgroBench covers a state-of-the-art range
of categories, including 203 crop categories and 682 disease categories, to
thoroughly evaluate VLM capabilities. In our evaluation on AgroBench, we reveal
that VLMs have room for improvement in fine-grained identification tasks.
Notably, in weed identification, most open-source VLMs perform close to random.
With our wide range of topics and expert-annotated categories, we analyze the
types of errors made by VLMs and suggest potential pathways for future VLM
development. Our dataset and code are available at
https://dahlian00.github.io/AgroBenchPage/ .

**中文摘要**：
Precise automated understanding of agricultural tasks such as disease
identification is essential for sustainable crop production. Recent advances in
vision-language models (VLMs) are expected to furt...

**GitHub仓库**：https://github.com/dahlian00/AgroBench/tree/main
**项目页面**：https://dahlian00.github.io/AgroBenchPage/
**模型功能**：暂无

**分析时间**：2025-08-04T17:49:44.323233
