# 基于区域聚类的视觉表征学习

**论文ID**：2507.20025
**英文标题**：Region-based Cluster Discrimination for Visual Representation Learning
**中文标题**：基于区域聚类的视觉表征学习
**论文地址**：https://arxiv.org/abs/2507.20025

**作者团队**：Yin Xie, Kaicheng Yang, Xiang An, Kun Wu, Yongle Zhao, Weimo Deng, Zimin Ran, Yumeng Wang, Ziyong Feng, Roy Miles, Ismail Elezi, Jiankang Deng
**发表日期**：2025-07-26

**英文摘要**：
Learning visual representations is foundational for a broad spectrum of
downstream tasks. Although recent vision-language contrastive models, such as
CLIP and SigLIP, have achieved impressive zero-shot performance via large-scale
vision-language alignment, their reliance on global representations constrains
their effectiveness for dense prediction tasks, such as grounding, OCR, and
segmentation. To address this gap, we introduce Region-Aware Cluster
Discrimination (RICE), a novel method that enhances region-level visual and OCR
capabilities. We first construct a billion-scale candidate region dataset and
propose a Region Transformer layer to extract rich regional semantics. We
further design a unified region cluster discrimination loss that jointly
supports object and OCR learning within a single classification framework,
enabling efficient and scalable distributed training on large-scale data.
Extensive experiments show that RICE consistently outperforms previous methods
on tasks, including segmentation, dense detection, and visual perception for
Multimodal Large Language Models (MLLMs). The pre-trained models have been
released at https://github.com/deepglint/MVT.

**中文摘要**：
学习视觉表征是广泛下游任务的基础。尽管最近的视觉-语言对比模型，如CLIP和SigLIP，通过大规模视觉-语言对齐取得了令人印象深刻的零样本性能，但它们对全局表征的依赖限制了它们在密集预测任务（如定位、OCR和分割）中的有效性。为解决这一差距，我们引入了区域感知聚类判别(RICE)，这是一种增强区域级视觉和OCR能力的新方法。我们首先构建了一个十亿规模的候选区域数据集，并提出了一种区域Transformer层来提取丰富的区域语义。我们进一步设计了一个统一的区域聚类判别损失，该损失在单一分类框架内共同支持对象和OCR学习，使大规模数据上的高效可扩展分布式训练成为可能。大量实验表明，RICE在包括分割、密集检测和多模态大语言模型(MLLMs)视觉感知在内的任务上始终优于先前的方法。预训练模型已在https://github.com/deepglint/MVT发布。

**GitHub仓库**：https://github.com/deepglint/MVT
**项目页面**：暂无
**模型功能**：基于区域聚类的视觉表征增强方法，提升密集预测任务性能

**分析时间**：2025-08-04T19:55:02.233696
