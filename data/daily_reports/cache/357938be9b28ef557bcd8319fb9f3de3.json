{
  "paper_id": "2507.20025",
  "paper_title": "Region-based Cluster Discrimination for Visual Representation Learning",
  "cache_time": 1754308502.2336967,
  "result": {
    "id": "2507.20025",
    "title_en": "Region-based Cluster Discrimination for Visual Representation Learning",
    "title_zh": "基于区域聚类的视觉表征学习",
    "url": "https://arxiv.org/abs/2507.20025",
    "authors": "Yin Xie, Kaicheng Yang, Xiang An, Kun Wu, Yongle Zhao, Weimo Deng, Zimin Ran, Yumeng Wang, Ziyong Feng, Roy Miles, Ismail Elezi, Jiankang Deng",
    "publish_date": "2025-07-26",
    "summary_en": "Learning visual representations is foundational for a broad spectrum of\ndownstream tasks. Although recent vision-language contrastive models, such as\nCLIP and SigLIP, have achieved impressive zero-shot performance via large-scale\nvision-language alignment, their reliance on global representations constrains\ntheir effectiveness for dense prediction tasks, such as grounding, OCR, and\nsegmentation. To address this gap, we introduce Region-Aware Cluster\nDiscrimination (RICE), a novel method that enhances region-level visual and OCR\ncapabilities. We first construct a billion-scale candidate region dataset and\npropose a Region Transformer layer to extract rich regional semantics. We\nfurther design a unified region cluster discrimination loss that jointly\nsupports object and OCR learning within a single classification framework,\nenabling efficient and scalable distributed training on large-scale data.\nExtensive experiments show that RICE consistently outperforms previous methods\non tasks, including segmentation, dense detection, and visual perception for\nMultimodal Large Language Models (MLLMs). The pre-trained models have been\nreleased at https://github.com/deepglint/MVT.",
    "summary_zh": "学习视觉表征是广泛下游任务的基础。尽管最近的视觉-语言对比模型，如CLIP和SigLIP，通过大规模视觉-语言对齐取得了令人印象深刻的零样本性能，但它们对全局表征的依赖限制了它们在密集预测任务（如定位、OCR和分割）中的有效性。为解决这一差距，我们引入了区域感知聚类判别(RICE)，这是一种增强区域级视觉和OCR能力的新方法。我们首先构建了一个十亿规模的候选区域数据集，并提出了一种区域Transformer层来提取丰富的区域语义。我们进一步设计了一个统一的区域聚类判别损失，该损失在单一分类框架内共同支持对象和OCR学习，使大规模数据上的高效可扩展分布式训练成为可能。大量实验表明，RICE在包括分割、密集检测和多模态大语言模型(MLLMs)视觉感知在内的任务上始终优于先前的方法。预训练模型已在https://github.com/deepglint/MVT发布。",
    "github_repo": "https://github.com/deepglint/MVT",
    "project_page": "暂无",
    "model_function": "基于区域聚类的视觉表征增强方法，提升密集预测任务性能",
    "analysis_time": "2025-08-04T19:55:02.233696"
  }
}