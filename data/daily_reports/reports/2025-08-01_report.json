[
    {
        "id": "2507.23726",
        "title_en": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving",
        "title_zh": "Seed-Prover：用于自动定理证明的深度和广度推理",
        "url": "https://arxiv.org/abs/2507.23726",
        "authors": "Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, Cheng Ren, Jiawei Shen, Wenlei Shi, Tong Sun, He Sun, Jiahui Wang, Siran Wang, Zhihong Wang, Chenrui Wei, Shufa Wei, Yonghui Wu, Yuchen Wu, Yihang Xia, Huajian Xin, Fan Yang, Huaiyuan Ying, Hongyi Yuan, Zheng Yuan, Tianyang Zhan, Chi Zhang, Yue Zhang, Ge Zhang, Tianyun Zhao, Jianqiu Zhao, Yichi Zhou, Thomas Hanwen Zhu",
        "publish_date": "2025-07-31",
        "summary_en": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\nSeed-Prover, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves 78.1% of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine Seed-Geometry, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.",
        "summary_zh": "大型语言模型(LLMs)通过利用带有长链式思维的强化学习展现了强大的数学推理能力，但由于仅使用自然语言时缺乏明确的监督信号，它们在定理证明方面仍然存在困难。专门的领域特定语言(如Lean)通过证明的形式验证提供清晰的监督，从而能够通过强化学习进行有效训练。在这项工作中，我们提出了Seed-Prover，一种基于引理的全证明推理模型。Seed-Prover可以根据Lean反馈、已证明的引理和自我总结来迭代地完善其证明。为了解决IMO级别的竞赛问题，我们设计了三种测试时推理策略，实现了深度和广度的推理。Seed-Prover证明了78.1%的已形式化的过去IMO问题，达到了MiniF2F的饱和度，并在PutnamBench上获得了超过50%的分数，大幅超越了之前的最先进水平。为了解决Lean中几何支持的不足，我们引入了几何推理引擎Seed-Geometry，其性能超过了之前的形式几何引擎。我们使用这两个系统参加了IMO 2025，并完全证明了6个问题中的5个。这项工作代表了自动数学推理的重大进展，证明了带有长链式思维的形式验证的有效性。",
        "github_repo": "https://github.com/ByteDance-Seed/Seed-Prover",
        "project_page": "暂无",
        "model_function": "基于Lean反馈迭代完善证明的定理证明模型，能解决IMO级别数学竞赛问题，并支持几何推理。",
        "analysis_time": "2025-08-04T17:47:34.432313"
    },
    {
        "id": "2507.23779",
        "title_en": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding",
        "title_zh": "Phi-Ground技术报告：提升GUI定位中的感知能力",
        "url": "https://arxiv.org/abs/2507.23779",
        "authors": "Miaosen Zhang, Ziqiang Xu, Jialiang Zhu, Qi Dai, Kai Qiu, Yifan Yang, Chong Luo, Tianyi Chen, Justin Wagle, Tim Franklin, Baining Guo",
        "publish_date": "2025-07-31",
        "summary_en": "With the development of multimodal reasoning models, Computer Use Agents\n(CUAs), akin to Jarvis from \"Iron Man\", are becoming a reality. GUI\ngrounding is a core component for CUAs to execute actual actions, similar to\nmechanical control in robotics, and it directly leads to the success or failure\nof the system. It determines actions such as clicking and typing, as well as\nrelated parameters like the coordinates for clicks. Current end-to-end\ngrounding models still achieve less than 65\\% accuracy on challenging\nbenchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from\nbeing ready for deployment. % , as a single misclick can result in unacceptable\nconsequences. In this work, we conduct an empirical study on the training of\ngrounding models, examining details from data collection to model training.\nUltimately, we developed the Phi-Ground model family, which achieves\nstate-of-the-art performance across all five grounding benchmarks for models\nunder 10B parameters in agent settings. In the end-to-end model setting, our\nmodel still achieves SOTA results with scores of \\textbf{43.2} on\nScreenSpot-pro and \\textbf{27.2} on UI-Vision. We believe that the\nvarious details discussed in this paper, along with our successes and failures,\nnot only clarify the construction of grounding models but also benefit other\nperception tasks. Project homepage:\nhttps://zhangmiaosen2000.github.io/Phi-Ground/{https://zhangmiaosen2000.github.io/Phi-Ground/}",
        "summary_zh": "随着多模态推理模型的发展，类似于\"钢铁侠\"中的Jarvis的计算机使用代理(CUAs)正成为现实。GUI定位是CUAs执行实际操作的核心组件，类似于机器人中的机械控制，它直接决定了系统的成功或失败。它决定了点击和键入等操作，以及点击等相关参数，如坐标。当前的端到端定位模型在ScreenSpot-pro和UI-Vision等具有挑战性的基准测试上仍低于65%的准确率，表明它们远未准备好部署，因为一次错误的点击可能导致不可接受的后果。在这项工作中，我们对定位模型的训练进行了实证研究，检查了从数据收集到模型训练的细节。最终，我们开发了Phi-Ground模型家族，在代理设置下，所有10B参数以下的模型在所有五个定位基准测试中都达到了最先进的性能。在端到端模型设置中，我们的模型在ScreenSpot-pro上仍取得了43.2分的SOTA结果，在UI-Vision上取得了27.2分的SOTA结果。我们相信，本文讨论的各种细节，以及我们的成功和失败，不仅阐明了定位模型的构建，也有益于其他感知任务。项目主页：https://zhangmiaosen2000.github.io/Phi-Ground/ GitHub仓库：https://github.com/zhangmiaosen2000/Phi-Ground 项目页面：https://zhangmiaosen2000.github.io/Phi-Ground/",
        "github_repo": "https://github.com/zhangmiaosen2000/Phi-Ground",
        "project_page": "https://zhangmiaosen2000.github.io/Phi-Ground/",
        "model_function": "提升计算机使用代理在GUI界面上的定位感知能力，实现精准点击和键入操作。",
        "analysis_time": "2025-08-04T17:47:53.353162"
    },
    {
        "id": "2507.23277",
        "title_en": "iLRM: An Iterative Large 3D Reconstruction Model",
        "title_zh": "iLRM：一种迭代式大型3D重建模型",
        "url": "https://arxiv.org/abs/2507.23277",
        "authors": "Gyeongjin Kang, Seungtae Nam, Xiangyu Sun, Sameh Khamis, Abdelrahman Mohamed, Eunbyung Park",
        "publish_date": "2025-07-31",
        "summary_en": "Feed-forward 3D modeling has emerged as a promising approach for rapid and\nhigh-quality 3D reconstruction. In particular, directly generating explicit 3D\nrepresentations, such as 3D Gaussian splatting, has attracted significant\nattention due to its fast and high-quality rendering, as well as numerous\napplications. However, many state-of-the-art methods, primarily based on\ntransformer architectures, suffer from severe scalability issues because they\nrely on full attention across image tokens from multiple input views, resulting\nin prohibitive computational costs as the number of views or image resolution\nincreases. Toward a scalable and efficient feed-forward 3D reconstruction, we\nintroduce an iterative Large 3D Reconstruction Model (iLRM) that generates 3D\nGaussian representations through an iterative refinement mechanism, guided by\nthree core principles: (1) decoupling the scene representation from input-view\nimages to enable compact 3D representations; (2) decomposing fully-attentional\nmulti-view interactions into a two-stage attention scheme to reduce\ncomputational costs; and (3) injecting high-resolution information at every\nlayer to achieve high-fidelity reconstruction. Experimental results on widely\nused datasets, such as RE10K and DL3DV, demonstrate that iLRM outperforms\nexisting methods in both reconstruction quality and speed. Notably, iLRM\nexhibits superior scalability, delivering significantly higher reconstruction\nquality under comparable computational cost by efficiently leveraging a larger\nnumber of input views.",
        "summary_zh": "前馈3D建模已成为一种快速高质量3D重建的前沿方法。特别是，直接生成显式3D表示（如3D高斯泼溅）因其快速高质量的渲染效果以及众多应用场景而受到广泛关注。然而，许多最先进的方法主要基于Transformer架构，存在严重的可扩展性问题，因为它们依赖于跨多个输入视图的图像令牌的全注意力机制，导致随着视图数量或图像分辨率的增加，计算成本变得过高。为了实现可扩展且高效的前馈3D重建，我们引入了一种迭代式大型3D重建模型(iLRM)，该模型通过迭代细化机制生成3D高斯表示，并遵循三个核心原则：(1)将场景表示与输入视图图像解耦，以实现紧凑的3D表示；(2)将全注意力的多视图交互分解为两阶段注意力方案，以降低计算成本；(3)在每个层注入高分辨率信息，以实现高保真度的重建。在RE10K和DL3DV等常用数据集上的实验结果表明，iLRM在重建质量和速度方面均优于现有方法。值得注意的是，iLRM表现出卓越的可扩展性，通过有效利用更多的输入视图，在可比的计算成本下提供显著更高的重建质量。",
        "github_repo": "https://github.com/Gynjn/iLRM",
        "project_page": "https://gynjn.github.io/iLRM/",
        "model_function": "迭代式3D重建模型，通过两阶段注意力方案实现高质量、高效率的3D高斯表示重建",
        "analysis_time": "2025-08-04T17:48:06.333775"
    },
    {
        "id": "2507.22879",
        "title_en": "RecGPT Technical Report",
        "title_zh": "RecGPT技术报告",
        "url": "https://arxiv.org/abs/2507.22879",
        "authors": "Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Mao Zhang, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou",
        "publish_date": "2025-07-30",
        "summary_en": "Recommender systems are among the most impactful applications of artificial\nintelligence, serving as critical infrastructure connecting users, merchants,\nand platforms. However, most current industrial systems remain heavily reliant\non historical co-occurrence patterns and log-fitting objectives, i.e.,\noptimizing for past user interactions without explicitly modeling user intent.\nThis log-fitting approach often leads to overfitting to narrow historical\npreferences, failing to capture users' evolving and latent interests. As a\nresult, it reinforces filter bubbles and long-tail phenomena, ultimately\nharming user experience and threatening the sustainability of the whole\nrecommendation ecosystem.\n  To address these challenges, we rethink the overall design paradigm of\nrecommender systems and propose RecGPT, a next-generation framework that places\nuser intent at the center of the recommendation pipeline. By integrating large\nlanguage models (LLMs) into key stages of user interest mining, item retrieval,\nand explanation generation, RecGPT transforms log-fitting recommendation into\nan intent-centric process. To effectively align general-purpose LLMs to the\nabove domain-specific recommendation tasks at scale, RecGPT incorporates a\nmulti-stage training paradigm, which integrates reasoning-enhanced\npre-alignment and self-training evolution, guided by a Human-LLM cooperative\njudge system. Currently, RecGPT has been fully deployed on the Taobao App.\nOnline experiments demonstrate that RecGPT achieves consistent performance\ngains across stakeholders: users benefit from increased content diversity and\nsatisfaction, merchants and the platform gain greater exposure and conversions.\nThese comprehensive improvement results across all stakeholders validates that\nLLM-driven, intent-centric design can foster a more sustainable and mutually\nbeneficial recommendation ecosystem.",
        "summary_zh": "推荐系统是人工智能最具影响力的应用之一，作为连接用户、商家和平台的关键基础设施。然而，当前大多数工业系统仍然严重依赖历史共现模式和日志拟合目标，即优化过去的用户交互而不明确建模用户意图。这种日志拟合方法往往导致对狭窄历史偏好的过拟合，无法捕捉用户不断演变的潜在兴趣。因此，它强化了过滤气泡和长尾现象，最终损害用户体验并威胁整个推荐生态系统的可持续性。为应对这些挑战，我们重新思考了推荐系统的整体设计范式，并提出RecGPT，这是一个以用户意图为中心的下一代推荐框架。通过将大型语言模型（LLMs）整合到用户兴趣挖掘、项目检索和解释生成的关键阶段，RecGPT将日志拟合推荐转变为以意图为中心的过程。为了有效地将通用LLMs大规模对齐到上述领域特定的推荐任务，RecGPT采用多阶段训练范式，该范式结合了推理增强的预对齐和自我训练演化，并由人-LLM协同判断系统指导。目前，RecGPT已在淘宝App上全面部署。在线实验表明，RecGPT在所有利益相关者中实现了一致的性能提升：用户从增加的内容多样性和满意度中受益，商家和平台获得了更大的曝光率和转化率。所有利益相关者这些全面的改进结果验证了LLM驱动的、以意图为中心的设计可以培育一个更可持续和互利共赢的推荐生态系统。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "以用户意图为中心的推荐框架，整合LLM实现兴趣挖掘、检索和解释生成，构建更可持续的推荐生态系统",
        "analysis_time": "2025-08-04T17:48:14.199948"
    },
    {
        "id": "2507.23682",
        "title_en": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action   Models",
        "title_zh": "villa-X：增强视觉-语言-动作模型中的潜在动作建模",
        "url": "https://arxiv.org/abs/2507.23682",
        "authors": "Xiaoyu Chen, Hangxing Wei, Pushi Zhang, Chuheng Zhang, Kaixin Wang, Yanjiang Guo, Rushuai Yang, Yucen Wang, Xinquan Xiao, Li Zhao, Jianyu Chen, Jiang Bian",
        "publish_date": "2025-07-31",
        "summary_en": "Visual-Language-Action (VLA) models have emerged as a popular paradigm for\nlearning robot manipulation policies that can follow language instructions and\ngeneralize to novel scenarios. Recent work has begun to explore the\nincorporation of latent actions, an abstract representation of visual change\nbetween two frames, into VLA pre-training. In this paper, we introduce villa-X,\na novel Visual-Language-Latent-Action (ViLLA) framework that advances latent\naction modeling for learning generalizable robot manipulation policies. Our\napproach improves both how latent actions are learned and how they are\nincorporated into VLA pre-training. Together, these contributions enable\nvilla-X to achieve superior performance across simulated environments including\nSIMPLER and LIBERO, as well as on two real-world robot setups including gripper\nand dexterous hand manipulation. We believe the ViLLA paradigm holds\nsignificant promise, and that our villa-X provides a strong foundation for\nfuture research.",
        "summary_zh": "视觉-语言-动作（VLA）模型已经成为一种流行的范式，用于学习能够遵循语言指令并泛化到新场景的机器人操作策略。最近的工作开始探索将潜在动作（两帧之间视觉变化的抽象表示）纳入VLA预训练中。在本文中，我们介绍了villa-X，这是一种新颖的视觉-语言-潜在动作（ViLLA）框架，它改进了潜在动作建模，用于学习可泛化的机器人操作策略。我们的方法改进了潜在动作的学习方式以及它们如何被纳入VLA预训练。这些贡献共同使villa-X能够在包括SIMPLER和LIBERO在内的模拟环境以及包括夹爪和灵巧手操作在内的两个真实机器人设置上实现卓越性能。我们认为ViLLA范式具有巨大潜力，而我们的villa-X为未来研究提供了坚实的基础。",
        "github_repo": "https://github.com/microsoft/villa-x/",
        "project_page": "https://microsoft.github.io/villa-x/",
        "model_function": "改进潜在动作建模，实现可泛化的机器人操作策略，遵循语言指令并适应新场景。",
        "analysis_time": "2025-08-04T17:48:25.597131"
    },
    {
        "id": "2507.22968",
        "title_en": "C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring   Challenges in Complex Conversations",
        "title_zh": "C3：探索复杂对话挑战的双语口语对话模型基准",
        "url": "https://arxiv.org/abs/2507.22968",
        "authors": "Chengqian Ma, Wei Tao, Yiwen Guo",
        "publish_date": "2025-07-30",
        "summary_en": "Spoken Dialogue Models (SDMs) have recently attracted significant attention\nfor their ability to generate voice responses directly to users' spoken\nqueries. Despite their increasing popularity, there exists a gap in research\nfocused on comprehensively understanding their practical effectiveness in\ncomprehending and emulating human conversations. This is especially true\ncompared to text-based Large Language Models (LLMs), which benefit from\nextensive benchmarking. Human voice interactions are inherently more complex\nthan text due to characteristics unique to spoken dialogue. Ambiguity poses one\nchallenge, stemming from semantic factors like polysemy, as well as\nphonological aspects such as heterograph, heteronyms, and stress patterns.\nAdditionally, context-dependency, like omission, coreference, and multi-turn\ninteraction, adds further complexity to human conversational dynamics. To\nilluminate the current state of SDM development and to address these\nchallenges, we present a benchmark dataset in this paper, which comprises 1,079\ninstances in English and Chinese. Accompanied by an LLM-based evaluation method\nthat closely aligns with human judgment, this dataset facilitates a\ncomprehensive exploration of the performance of SDMs in tackling these\npractical challenges.",
        "summary_zh": "口语对话模型(SDMs)最近因其能够直接根据用户的语音查询生成语音响应而引起了广泛关注。尽管它们日益流行，但在全面理解其实际有效性方面仍存在研究空白，特别是在理解和模拟人类对话方面。与基于文本的大型语言模型(LLMs)相比，这一点尤为明显，因为后者受益于广泛的基准测试。人类语音交互本质上比文本更复杂，这是由于口语对话特有的特征造成的。歧义是一个挑战，源于多义性等语义因素，以及异形词、多音字和重音模式等音韵方面。此外，上下文依赖性，如省略、指代和多轮交互，进一步增加了人类对话动态的复杂性。为了阐明SDM开发的现状并解决这些挑战，我们在本文中提出了一个基准数据集，包含1079个英语和中文实例。伴随一个与人类判断紧密对齐的基于LLM的评估方法，该数据集促进了对SDM应对这些实际挑战性能的全面探索。",
        "github_repo": "https://github.com/step-out/C3",
        "project_page": "https://step-out.github.io/C3-web/",
        "model_function": "提供双语基准数据集和评估方法，用于测试口语对话模型在复杂对话场景中的表现。",
        "analysis_time": "2025-08-04T17:48:35.782752"
    },
    {
        "id": "2507.21509",
        "title_en": "Persona Vectors: Monitoring and Controlling Character Traits in Language   Models",
        "title_zh": "人物向量：监控和控制语言模型中的性格特征",
        "url": "https://arxiv.org/abs/2507.21509",
        "authors": "Runjin Chen, Andy Arditi, Henry Sleight, Owain Evans, Jack Lindsey",
        "publish_date": "2025-07-29",
        "summary_en": "Large language models interact with users through a simulated 'Assistant'\npersona. While the Assistant is typically trained to be helpful, harmless, and\nhonest, it sometimes deviates from these ideals. In this paper, we identify\ndirections in the model's activation space-persona vectors-underlying several\ntraits, such as evil, sycophancy, and propensity to hallucinate. We confirm\nthat these vectors can be used to monitor fluctuations in the Assistant's\npersonality at deployment time. We then apply persona vectors to predict and\ncontrol personality shifts that occur during training. We find that both\nintended and unintended personality changes after finetuning are strongly\ncorrelated with shifts along the relevant persona vectors. These shifts can be\nmitigated through post-hoc intervention, or avoided in the first place with a\nnew preventative steering method. Moreover, persona vectors can be used to flag\ntraining data that will produce undesirable personality changes, both at the\ndataset level and the individual sample level. Our method for extracting\npersona vectors is automated and can be applied to any personality trait of\ninterest, given only a natural-language description.",
        "summary_zh": "大型语言模型通过模拟的'助手'角色与用户交互。虽然助手通常被训练得乐于助人、无害且诚实，但它有时会偏离这些理想特质。在本文中，我们确定了模型激活空间中的一些方向——人物向量，这些向量构成了多种特质的基础，如邪恶、奉承和幻觉倾向。我们证实这些向量可用于在部署时监控助手性格的波动。然后我们应用人物向量来预测和控制训练过程中发生的性格转变。我们发现，微调后的预期和非预期性格变化都与相关人物向量方向上的转变密切相关。这些转变可以通过事后干预来减轻，或者通过一种新的预防性引导方法从一开始就避免。此外，人物向量可用于标记会产生不良性格变化的训练数据，无论是在数据集级别还是单个样本级别。我们提取人物向量的方法是自动化的，只需自然语言描述，即可应用于任何感兴趣的个性特质。",
        "github_repo": "https://github.com/safety-research/persona_vectors/tree/main",
        "project_page": "暂无",
        "model_function": "通过人物向量实现对语言模型性格特征的监测、预测和干预控制。",
        "analysis_time": "2025-08-04T17:48:46.571412"
    },
    {
        "id": "2507.23698",
        "title_en": "Scalable Multi-Task Reinforcement Learning for Generalizable Spatial   Intelligence in Visuomotor Agents",
        "title_zh": "面向视觉运动智能体可泛化空间智能的可扩展多任务强化学习",
        "url": "https://arxiv.org/abs/2507.23698",
        "authors": "Shaofei Cai, Zhancun Mu, Haiwen Xia, Bowei Zhang, Anji Liu, Yitao Liang",
        "publish_date": "2025-07-31",
        "summary_en": "While Reinforcement Learning (RL) has achieved remarkable success in language\nmodeling, its triumph hasn't yet fully translated to visuomotor agents. A\nprimary challenge in RL models is their tendency to overfit specific tasks or\nenvironments, thereby hindering the acquisition of generalizable behaviors\nacross diverse settings. This paper provides a preliminary answer to this\nchallenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can\nachieve zero-shot generalization to unseen worlds. Specifically, we explore\nRL's potential to enhance generalizable spatial reasoning and interaction\ncapabilities in 3D worlds. To address challenges in multi-task RL\nrepresentation, we analyze and establish cross-view goal specification as a\nunified multi-task goal space for visuomotor policies. Furthermore, to overcome\nthe significant bottleneck of manual task design, we propose automated task\nsynthesis within the highly customizable Minecraft environment for large-scale\nmulti-task RL training, and we construct an efficient distributed RL framework\nto support this. Experimental results show RL significantly boosts interaction\nsuccess rates by 4times and enables zero-shot generalization of spatial\nreasoning across diverse environments, including real-world settings. Our\nfindings underscore the immense potential of RL training in 3D simulated\nenvironments, especially those amenable to large-scale task generation, for\nsignificantly advancing visuomotor agents' spatial reasoning.",
        "summary_zh": "虽然强化学习(RL)在语言建模方面取得了显著成功，但其成就尚未完全转化为视觉运动智能体。RL模型的一个主要挑战是它们倾向于过度拟合特定任务或环境，从而阻碍了在各种环境中获取可泛化的行为。本文通过证明在Minecraft中经过RL微调的视觉运动智能体能够实现对未见世界的零样本泛化，为这一挑战提供了初步答案。具体而言，我们探索了RL增强3D世界中可泛化空间推理和交互能力的潜力。为了解决多任务RL表示中的挑战，我们分析和建立了跨视图目标规范作为视觉运动策略的统一多任务目标空间。此外，为了克服手动任务设计的重要瓶颈，我们在高度可定制的Minecraft环境中提出了自动化任务合成，用于大规模多任务RL训练，并构建了一个高效的分布式RL框架来支持这一点。实验结果表明，RL显著将交互成功率提高了4倍，并实现了空间推理在包括现实世界环境在内的各种环境中的零样本泛化。我们的研究结果强调了在3D模拟环境中进行RL训练的巨大潜力，特别是那些适合大规模任务生成的环境，对于显著提升视觉运动智能体的空间推理能力。",
        "github_repo": "https://github.com/CraftJarvis/ROCKET-3",
        "project_page": "暂无",
        "model_function": "通过可扩展多任务强化学习提升视觉运动智能体在3D环境中的空间推理能力和零样本泛化性能。",
        "analysis_time": "2025-08-04T17:49:02.690577"
    },
    {
        "id": "2507.23374",
        "title_en": "NeRF Is a Valuable Assistant for 3D Gaussian Splatting",
        "title_zh": "NeRF是3D高斯溅射的有价值助手",
        "url": "https://arxiv.org/abs/2507.23374",
        "authors": "Shuangkang Fang, I-Chao Shen, Takeo Igarashi, Yufeng Wang, ZeSheng Wang, Yi Yang, Wenrui Ding, Shuchang Zhou",
        "publish_date": "2025-07-31",
        "summary_en": "We introduce NeRF-GS, a novel framework that jointly optimizes Neural\nRadiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). This framework\nleverages the inherent continuous spatial representation of NeRF to mitigate\nseveral limitations of 3DGS, including sensitivity to Gaussian initialization,\nlimited spatial awareness, and weak inter-Gaussian correlations, thereby\nenhancing its performance. In NeRF-GS, we revisit the design of 3DGS and\nprogressively align its spatial features with NeRF, enabling both\nrepresentations to be optimized within the same scene through shared 3D spatial\ninformation. We further address the formal distinctions between the two\napproaches by optimizing residual vectors for both implicit features and\nGaussian positions to enhance the personalized capabilities of 3DGS.\nExperimental results on benchmark datasets show that NeRF-GS surpasses existing\nmethods and achieves state-of-the-art performance. This outcome confirms that\nNeRF and 3DGS are complementary rather than competing, offering new insights\ninto hybrid approaches that combine 3DGS and NeRF for efficient 3D scene\nrepresentation.",
        "summary_zh": "我们提出了NeRF-GS，一种联合优化神经辐射场(NeRF)和3D高斯溅射(3DGS)的新颖框架。该框架利用NeRF固有的连续空间表示来缓解3DGS的几个局限性，包括对高斯初始化的敏感性、有限的空间感知能力和弱高斯间相关性，从而提高其性能。在NeRF-GS中，我们重新审视了3DGS的设计，并逐步将其空间特征与NeRF对齐，通过共享的3D空间信息使两种表示能够在同一场景内进行优化。我们进一步通过优化隐式特征和高斯位置的残差向量来解决两种方法之间的形式差异，以增强3DGS的个性化能力。在基准数据集上的实验结果表明，NeRF-GS超越了现有方法并取得了最先进的性能。这一结果证实了NeRF和3DGS是互补而非竞争关系，为结合3DGS和NeRF的高效3D场景表示的混合方法提供了新的见解。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "联合优化NeRF和3DGS，利用NeRF的连续空间表示增强3DGS性能，实现互补的高效3D场景表示。",
        "analysis_time": "2025-08-04T17:49:16.497628"
    },
    {
        "id": "2507.21584",
        "title_en": "TARS: MinMax Token-Adaptive Preference Strategy for Hallucination   Reduction in MLLMs",
        "title_zh": "TARS：用于多模态大语言模型中减少幻觉的MinMax令牌自适应偏好策略",
        "url": "https://arxiv.org/abs/2507.21584",
        "authors": "Kejia Zhang, Keda Tao, Zhiming Luo, Chang Liu, Jiasheng Tang, Huan Wang",
        "publish_date": "2025-07-29",
        "summary_en": "Multimodal large language models (MLLMs) enable vision-language reasoning,\nyet often generate plausible outputs that are factually incorrect or visually\nungrounded, thereby compromising their reliability. Direct preference\noptimization (DPO) is a common strategy for correcting hallucinations by\naligning model outputs with human preferences. Existing DPO strategies\ntypically treat hallucination-related preferences as fixed targets, relying on\nstatic supervision signals during training. This approach tends to overfit to\nsuperficial linguistic cues in preference data, leading to distributional\nrigidity and spurious correlations that impair grounding in causally relevant\nvisual information. To overcome this limitation, we propose TARS, a\ntoken-adaptive preference strategy that reformulates DPO as a min-max\noptimization problem. TARS maximizes token-level distributional shifts under\nsemantic constraints to simulate alignment uncertainty, and simultaneously\nminimizes the expected preference loss under these controlled perturbations.\nThis joint objective preserves causal grounding while mitigating overfitting to\npreference patterns, thereby reducing hallucinations in multimodal reasoning.\nWe evaluate TARS on multiple hallucination benchmarks and find consistently\nstrong performance. Using only 4.8k preference samples and no expert feedback,\nTARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition\nvalue from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on\nseveral key metrics.",
        "summary_zh": "多模态大语言模型(MLLMs)使视觉语言推理成为可能，但常常生成看似合理但事实错误或视觉基础不足的输出，从而降低了它们的可靠性。直接偏好优化(DPO)是一种通过将模型输出与人类偏好对齐来纠正幻觉的常见策略。现有的DPO策略通常将幻觉相关偏好视为固定目标，在训练期间依赖静态监督信号。这种方法倾向于过度拟合偏好数据中的表面语言线索，导致分布刚性和虚假相关性，损害了对因果相关视觉信息的理解。为了克服这一限制，我们提出了TARS，一种令牌自适应偏好策略，将DPO重新表述为最小-最大优化问题。TARS在语义约束下最大化令牌级别的分布偏移，以模拟对齐的不确定性，同时在这些受控扰动下最小化期望偏好损失。这种联合目标保留了因果基础，同时减轻了对偏好模式的过度拟合，从而减少多模态推理中的幻觉。我们在多个幻觉基准上评估了TARS，发现了一致的强大性能。仅使用4.8k偏好样本且无需专家反馈，TARS将幻觉率从26.4%降低到13.2%，并将认知值从2.5降低到0.4。它在多个关键指标上优于标准DPO，并匹配GPT-4o的性能。",
        "github_repo": "https://github.com/KejiaZhang-Robust/TARS",
        "project_page": "https://kejiazhang-robust.github.io/tars_web/",
        "model_function": "通过令牌自适应偏好策略减少多模态大语言模型中的幻觉，提高视觉语言推理的可靠性。",
        "analysis_time": "2025-08-04T17:49:24.367143"
    },
    {
        "id": "2507.20519",
        "title_en": "AgroBench: Vision-Language Model Benchmark in Agriculture",
        "title_zh": "AgroBench: Vision-Language Model Benchmark in Agriculture",
        "url": "https://arxiv.org/abs/2507.20519",
        "authors": "Risa Shinoda, Nakamasa Inoue, Hirokatsu Kataoka, Masaki Onishi, Yoshitaka Ushiku",
        "publish_date": "2025-07-28",
        "summary_en": "Precise automated understanding of agricultural tasks such as disease\nidentification is essential for sustainable crop production. Recent advances in\nvision-language models (VLMs) are expected to further expand the range of\nagricultural tasks by facilitating human-model interaction through easy,\ntext-based communication. Here, we introduce AgroBench (Agronomist AI\nBenchmark), a benchmark for evaluating VLM models across seven agricultural\ntopics, covering key areas in agricultural engineering and relevant to\nreal-world farming. Unlike recent agricultural VLM benchmarks, AgroBench is\nannotated by expert agronomists. Our AgroBench covers a state-of-the-art range\nof categories, including 203 crop categories and 682 disease categories, to\nthoroughly evaluate VLM capabilities. In our evaluation on AgroBench, we reveal\nthat VLMs have room for improvement in fine-grained identification tasks.\nNotably, in weed identification, most open-source VLMs perform close to random.\nWith our wide range of topics and expert-annotated categories, we analyze the\ntypes of errors made by VLMs and suggest potential pathways for future VLM\ndevelopment. Our dataset and code are available at\nhttps://dahlian00.github.io/AgroBenchPage/ .",
        "summary_zh": "Precise automated understanding of agricultural tasks such as disease\nidentification is essential for sustainable crop production. Recent advances in\nvision-language models (VLMs) are expected to furt...",
        "github_repo": "https://github.com/dahlian00/AgroBench/tree/main",
        "project_page": "https://dahlian00.github.io/AgroBenchPage/",
        "model_function": "暂无",
        "analysis_time": "2025-08-04T17:49:44.323233"
    },
    {
        "id": "2507.23632",
        "title_en": "On the Expressiveness of Softmax Attention: A Recurrent Neural Network   Perspective",
        "title_zh": "论Softmax注意力的表达能力：循环神经网络视角",
        "url": "https://arxiv.org/abs/2507.23632",
        "authors": "Gabriel Mongaras, Eric C. Larson",
        "publish_date": "2025-07-31",
        "summary_en": "Since its introduction, softmax attention has become the backbone of modern\ntransformer architectures due to its expressiveness and scalability across a\nwide range of tasks. However, the main drawback of softmax attention is the\nquadratic memory requirement and computational complexity with respect to the\nsequence length. By replacing the softmax nonlinearity, linear attention and\nsimilar methods have been introduced to avoid the quadratic bottleneck of\nsoftmax attention. Despite these linear forms of attention being derived from\nthe original softmax formulation, they typically lag in terms of downstream\naccuracy. While strong intuition of the softmax nonlinearity on the query and\nkey inner product suggests that it has desirable properties compared to other\nnonlinearities, the question of why this discrepancy exists still remains\nunanswered. This work demonstrates that linear attention is an approximation of\nsoftmax attention by deriving the recurrent form of softmax attention. Using\nthis form, each part of softmax attention can be described in the language of\nrecurrent neural networks (RNNs). Describing softmax attention as an RNN allows\nfor the ablation of the components of softmax attention to understand the\nimportance of each part and how they interact. In this way, our work helps\nexplain why softmax attention is more expressive than its counterparts.",
        "summary_zh": "自Softmax注意力机制引入以来，由于其广泛的任务表达能力和可扩展性，它已成为现代Transformer架构的骨干。然而，Softmax注意力的主要缺点是其对序列长度的二次方内存需求和计算复杂度。通过替换Softmax非线性函数，线性注意力及类似方法被提出以避免Softmax注意力的二次瓶颈。尽管这些线性注意力形式源于原始Softmax公式，但在下游任务准确性方面通常表现较差。虽然Softmax非线性在查询和键内积上的强烈直觉表明它比其他非线性函数具有更理想的特性，但这种差异存在的原因仍未得到解答。本研究通过推导Softmax注意力的循环形式，证明了线性注意力是Softmax注意力的一种近似。利用这种形式，Softmax注意力的每个部分都可以用循环神经网络(RNN)的语言来描述。将Softmax注意力描述为RNN，可以对Softmax注意力组件进行消融研究，以理解每个部分的重要性及其相互作用方式。通过这种方式，我们的工作有助于解释为什么Softmax注意力比其对应方法更具表现力。",
        "github_repo": "https://github.com/gmongaras/On-the-Expressiveness-of-Softmax-Attention-A-Recurrent-Neural-Network-Perspective",
        "project_page": "暂无",
        "model_function": "分析Softmax注意力的循环神经网络表示，解释其比线性注意力更具表现力的原因。",
        "analysis_time": "2025-08-04T17:49:55.295239"
    },
    {
        "id": "2507.23436",
        "title_en": "Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for   Culturally Diverse Art Style Classification",
        "title_zh": "超越线性瓶颈：基于样条线的文化多样性艺术风格分类知识蒸馏",
        "url": "https://arxiv.org/abs/2507.23436",
        "authors": "Abdellah Zakaria Sellam, Salah Eddine Bekhouche, Cosimo Distante, Abdelmalik Taleb-Ahmed",
        "publish_date": "2025-07-31",
        "summary_en": "Art style classification remains a formidable challenge in computational\naesthetics due to the scarcity of expertly labeled datasets and the intricate,\noften nonlinear interplay of stylistic elements. While recent dual-teacher\nself-supervised frameworks reduce reliance on labeled data, their linear\nprojection layers and localized focus struggle to model global compositional\ncontext and complex style-feature interactions. We enhance the dual-teacher\nknowledge distillation framework to address these limitations by replacing\nconventional MLP projection and prediction heads with Kolmogorov-Arnold\nNetworks (KANs). Our approach retains complementary guidance from two teacher\nnetworks, one emphasizing localized texture and brushstroke patterns, the other\ncapturing broader stylistic hierarchies while leveraging KANs' spline-based\nactivations to model nonlinear feature correlations with mathematical\nprecision. Experiments on WikiArt and Pandora18k demonstrate that our approach\noutperforms the base dual teacher architecture in Top-1 accuracy. Our findings\nhighlight the importance of KANs in disentangling complex style manifolds,\nleading to better linear probe accuracy than MLP projections.",
        "summary_zh": "艺术风格分类在计算美学中仍然是一个严峻的挑战，这主要是由于专家标记数据集的稀缺以及艺术风格元素之间复杂且通常是非线性的相互作用。尽管最近的双教师自监督框架减少了对标记数据的依赖，但其线性投影层和局部化关注难以建模全局构图上下文和复杂的风格-特征相互作用。我们通过用Kolmogorov-Arnold网络(KANs)替代传统的MLP投影和预测头来增强双教师知识蒸馏框架，以解决这些局限性。我们的方法保留了两个教师网络的互补指导，一个强调局部纹理和笔触模式，另一个捕捉更广泛的风格层次结构，同时利用KANs的基于样条线的激活函数以数学精度建模非线性特征相关性。在WikiArt和Pandora18k上的实验表明，我们的方法在Top-1准确率上优于基础双教师架构。我们的研究结果强调了KANs在解耦复杂风格流形方面的重要性，导致比MLP投影更好的线性探测准确率。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "基于KANs的双教师知识蒸馏框架，用于文化多样性艺术风格分类，有效建模非线性特征相关性，提高分类准确率。",
        "analysis_time": "2025-08-04T17:50:05.672980"
    },
    {
        "id": "2507.14793",
        "title_en": "Flow Equivariant Recurrent Neural Networks",
        "title_zh": "流等价循环神经网络",
        "url": "https://arxiv.org/abs/2507.14793",
        "authors": "T. Anderson Keller",
        "publish_date": "2025-07-20",
        "summary_en": "Data arrives at our senses as a continuous stream, smoothly transforming from\none instant to the next. These smooth transformations can be viewed as\ncontinuous symmetries of the environment that we inhabit, defining equivalence\nrelations between stimuli over time. In machine learning, neural network\narchitectures that respect symmetries of their data are called equivariant and\nhave provable benefits in terms of generalization ability and sample\nefficiency. To date, however, equivariance has been considered only for static\ntransformations and feed-forward networks, limiting its applicability to\nsequence models, such as recurrent neural networks (RNNs), and corresponding\ntime-parameterized sequence transformations. In this work, we extend\nequivariant network theory to this regime of `flows' -- one-parameter Lie\nsubgroups capturing natural transformations over time, such as visual motion.\nWe begin by showing that standard RNNs are generally not flow equivariant:\ntheir hidden states fail to transform in a geometrically structured manner for\nmoving stimuli. We then show how flow equivariance can be introduced, and\ndemonstrate that these models significantly outperform their non-equivariant\ncounterparts in terms of training speed, length generalization, and velocity\ngeneralization, on both next step prediction and sequence classification. We\npresent this work as a first step towards building sequence models that respect\nthe time-parameterized symmetries which govern the world around us.",
        "summary_zh": "数据以连续流的形式到达我们的感官，从一个瞬间平滑地转变为下一个瞬间。这些平滑变换可以被视为我们所居住环境的连续对称性，定义了随时间变化的刺激之间的等价关系。在机器学习中，尊重其数据对称性的神经网络架构被称为等变的，并且在泛化能力和样本效率方面具有可证明的优势。然而，迄今为止，等变性仅被考虑用于静态变换和前馈网络，这限制了其在序列模型（如循环神经网络（RNN））以及相应的时间参数化序列变换中的应用。在这项工作中，我们将等变网络理论扩展到'流'这一领域——捕获随时间自然变换的单参数李子群，例如视觉运动。我们首先证明标准的RNN通常不是流等变的：对于移动的刺激，它们的隐藏状态未能以几何结构化的方式进行变换。然后我们展示了如何引入流等变性，并证明这些模型在训练速度、长度泛化和速度泛化方面显著优于其非等变的对应模型，无论是在下一步预测还是序列分类任务中。我们提出这项工作作为构建尊重支配我们周围世界的时间参数化对称性的序列模型的第一步。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "流等价循环神经网络，处理时间连续变换的序列数据，提升训练速度和泛化能力。",
        "analysis_time": "2025-08-04T17:50:16.959011"
    },
    {
        "id": "2507.23404",
        "title_en": "Enhanced Arabic Text Retrieval with Attentive Relevance Scoring",
        "title_zh": "基于注意力相关性评分的增强型阿拉伯语文本检索",
        "url": "https://arxiv.org/abs/2507.23404",
        "authors": "Salah Eddine Bekhouche, Azeddine Benlamoudi, Yazid Bounab, Fadi Dornaika, Abdenour Hadid",
        "publish_date": "2025-07-31",
        "summary_en": "Arabic poses a particular challenge for natural language processing (NLP) and\ninformation retrieval (IR) due to its complex morphology, optional diacritics\nand the coexistence of Modern Standard Arabic (MSA) and various dialects.\nDespite the growing global significance of Arabic, it is still underrepresented\nin NLP research and benchmark resources. In this paper, we present an enhanced\nDense Passage Retrieval (DPR) framework developed specifically for Arabic. At\nthe core of our approach is a novel Attentive Relevance Scoring (ARS) that\nreplaces standard interaction mechanisms with an adaptive scoring function that\nmore effectively models the semantic relevance between questions and passages.\nOur method integrates pre-trained Arabic language models and architectural\nrefinements to improve retrieval performance and significantly increase ranking\naccuracy when answering Arabic questions. The code is made publicly available\nat https://github.com/Bekhouche/APR{GitHub}.",
        "summary_zh": "阿拉伯语由于其复杂的形态学、可选的变音符号以及现代标准阿拉伯语(MSA)和各种方言共存的特点，对自然语言处理(NLP)和信息检索(IR)构成了特殊挑战。尽管阿拉伯语的全球重要性日益增长，但在NLP研究和基准资源中仍然代表性不足。在本文中，我们提出了一个专门为阿拉伯语开发的增强型密集段落检索(DPR)框架。我们方法的核心是一种新颖的注意力相关性评分(ARS)，它用自适应评分函数替代了标准的交互机制，该函数能更有效地建模问题与段落之间的语义相关性。我们的方法集成了预训练的阿拉伯语语言模型和架构改进，以提高检索性能，并在回答阿拉伯语问题时显著提高排序准确性。代码已在https://github.com/Bekhouche/APR上公开。",
        "github_repo": "https://github.com/Bekhouche/APR",
        "project_page": "暂无",
        "model_function": "为阿拉伯语文本检索提供增强的密集段落检索框架，通过注意力相关性评分机制提高语义相关性和排序准确性。",
        "analysis_time": "2025-08-04T17:50:24.407430"
    },
    {
        "id": "2507.23257",
        "title_en": "Efficient Machine Unlearning via Influence Approximation",
        "title_zh": "基于影响近似的高效机器遗忘学习",
        "url": "https://arxiv.org/abs/2507.23257",
        "authors": "Jiawei Liu, Chenwang Wu, Defu Lian, Enhong Chen",
        "publish_date": "2025-07-31",
        "summary_en": "Due to growing privacy concerns, machine unlearning, which aims at enabling\nmachine learning models to ``forget\" specific training data, has received\nincreasing attention. Among existing methods, influence-based unlearning has\nemerged as a prominent approach due to its ability to estimate the impact of\nindividual training samples on model parameters without retraining. However,\nthis approach suffers from prohibitive computational overhead arising from the\nnecessity to compute the Hessian matrix and its inverse across all training\nsamples and parameters, rendering it impractical for large-scale models and\nscenarios involving frequent data deletion requests. This highlights the\ndifficulty of forgetting. Inspired by cognitive science, which suggests that\nmemorizing is easier than forgetting, this paper establishes a theoretical link\nbetween memorizing (incremental learning) and forgetting (unlearning). This\nconnection allows machine unlearning to be addressed from the perspective of\nincremental learning. Unlike the time-consuming Hessian computations in\nunlearning (forgetting), incremental learning (memorizing) typically relies on\nmore efficient gradient optimization, which supports the aforementioned\ncognitive theory. Based on this connection, we introduce the Influence\nApproximation Unlearning (IAU) algorithm for efficient machine unlearning from\nthe incremental perspective. Extensive empirical evaluations demonstrate that\nIAU achieves a superior balance among removal guarantee, unlearning efficiency,\nand comparable model utility, while outperforming state-of-the-art methods\nacross diverse datasets and model architectures. Our code is available at\nhttps://github.com/Lolo1222/IAU.",
        "summary_zh": "随着隐私问题的日益增长，旨在使机器学习模型能够\"忘记\"特定训练数据的机器遗忘学习技术受到了越来越多的关注。在现有方法中，基于影响的遗忘学习已成为一种突出方法，因为它能够在不重新训练的情况下估计单个训练样本对模型参数的影响。然而，这种方法需要计算所有训练样本和参数的Hessian矩阵及其逆矩阵，导致计算开销过大，使其对于大规模模型和涉及频繁数据删除请求的场景不切实际。这凸显了遗忘的难度。受认知科学的启发——认知科学表明记忆比遗忘更容易，本文建立了记忆（增量学习）与遗忘（遗忘学习）之间的理论联系。这种联系使得可以从增量学习的角度解决机器遗忘学习问题。与遗忘学习（遗忘）中耗时的Hessian计算不同，增量学习（记忆）通常依赖于更高效的梯度优化，这支持了上述认知理论。基于这种联系，我们提出了影响近似遗忘学习（IAU）算法，从增量学习的角度实现高效的机器遗忘学习。大量的经验评估表明，IAU在移除保证、遗忘效率和可比的模型效用之间取得了优越的平衡，并且在各种数据集和模型架构上优于最先进的方法。我们的代码可在 https://github.com/Lolo1222/IAU 获取。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "高效实现机器遗忘学习，通过影响近似算法平衡移除保证、效率和模型效用。",
        "analysis_time": "2025-08-04T17:50:36.792526"
    }
]