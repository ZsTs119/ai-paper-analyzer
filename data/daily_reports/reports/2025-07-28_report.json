[
    {
        "id": "2507.20198",
        "title_en": "When Tokens Talk Too Much: A Survey of Multimodal Long-Context Token   Compression across Images, Videos, and Audios",
        "title_zh": "当token过多说话时：跨图像、视频和音频的多模态长上下文token压缩综述",
        "url": "https://arxiv.org/abs/2507.20198",
        "authors": "Kele Shao, Keda Tao, Kejia Zhang, Sicheng Feng, Mu Cai, Yuzhang Shang, Haoxuan You, Can Qin, Yang Sui, Huan Wang",
        "publish_date": "2025-07-27",
        "summary_en": "Multimodal large language models (MLLMs) have made remarkable strides,\nlargely driven by their ability to process increasingly long and complex\ncontexts, such as high-resolution images, extended video sequences, and lengthy\naudio input. While this ability significantly enhances MLLM capabilities, it\nintroduces substantial computational challenges, primarily due to the quadratic\ncomplexity of self-attention mechanisms with numerous input tokens. To mitigate\nthese bottlenecks, token compression has emerged as an auspicious and critical\napproach, efficiently reducing the number of tokens during both training and\ninference. In this paper, we present the first systematic survey and synthesis\nof the burgeoning field of multimodal long context token compression.\nRecognizing that effective compression strategies are deeply tied to the unique\ncharacteristics and redundancies of each modality, we categorize existing\napproaches by their primary data focus, enabling researchers to quickly access\nand learn methods tailored to their specific area of interest: (1)\nimage-centric compression, which addresses spatial redundancy in visual data;\n(2) video-centric compression, which tackles spatio-temporal redundancy in\ndynamic sequences; and (3) audio-centric compression, which handles temporal\nand spectral redundancy in acoustic signals. Beyond this modality-driven\ncategorization, we further dissect methods based on their underlying\nmechanisms, including transformation-based, similarity-based, attention-based,\nand query-based approaches. By providing a comprehensive and structured\noverview, this survey aims to consolidate current progress, identify key\nchallenges, and inspire future research directions in this rapidly evolving\ndomain. We also maintain a public repository to continuously track and update\nthe latest advances in this promising area.",
        "summary_zh": "多模态大型语言模型(MLLMs)取得了显著进展，这主要得益于它们处理越来越长和复杂上下文的能力，例如高分辨率图像、扩展的视频序列和长时间的音频输入。虽然这种能力显著增强了MLLM的能力，但它也带来了重大的计算挑战，主要由于自注意力机制与大量输入token之间的二次方复杂性。为了缓解这些瓶颈，token压缩已成为一种有前景且关键的方法，有效地减少了训练和推理过程中的token数量。在本文中，我们提出了对新兴的多模态长上下文token压缩领域的首次系统性综述和综合。认识到有效的压缩策略与每种模态的独特特征和冗余性密切相关，我们根据其主要数据焦点对现有方法进行分类，使研究人员能够快速访问和学习适合其特定兴趣领域的方法：(1)以图像为中心的压缩，解决视觉数据中的空间冗余；(2)以视频为中心的压缩，处理动态序列中的时空冗余；(3)以音频为中心的压缩，处理声学信号中的时间和频谱冗余。除了这种模态驱动的分类外，我们还进一步基于其底层机制对方法进行剖析，包括基于变换的、基于相似度的、基于注意力的和基于查询的方法。通过提供全面和结构化的概述，本综述旨在巩固当前进展，确定关键挑战，并激发这个快速发展的领域中未来研究方向。我们还维护了一个公共仓库，以持续跟踪和更新这个有前景领域的最新进展。",
        "github_repo": "https://github.com/cokeshao/Awesome-Multimodal-Token-Compression",
        "project_page": "https://github.com/cokeshao/Awesome-Multimodal-Token-Compression",
        "model_function": "综述多模态长上下文token压缩方法，分类图像、视频和音频的压缩技术，为研究人员提供系统性参考",
        "analysis_time": "2025-08-04T20:04:37.427211"
    },
    {
        "id": "2507.18553",
        "title_en": "The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane   Algorithm",
        "title_zh": "大型语言模型量化的几何学：GPTQ作为Babai的最接近平面算法",
        "url": "https://arxiv.org/abs/2507.18553",
        "authors": "Jiale Chen, Torsten Hoefler, Dan Alistarh",
        "publish_date": "2025-07-24",
        "summary_en": "Quantizing the weights of large language models (LLMs) from 16-bit to lower\nbitwidth is the de facto approach to deploy massive transformers onto more\naffordable accelerators. GPTQ emerged as one of the standard methods for\none-shot post-training quantization at LLM scale. Yet, its inner workings are\ndescribed as a sequence of ad-hoc algebraic updates that obscure any geometric\nmeaning or worst-case guarantees. In this work, we show that, when executed\nback-to-front (from the last to first dimension) for a linear layer, GPTQ is\nmathematically identical to Babai's nearest plane algorithm for the classical\nclosest vector problem (CVP) on a lattice defined by the Hessian matrix of the\nlayer's inputs. This equivalence is based on a sophisticated mathematical\nargument, and has two analytical consequences: (i) the GPTQ error propagation\nstep gains an intuitive geometric interpretation; (ii) GPTQ inherits the error\nupper bound of Babai's algorithm under the no-clipping condition. Taken\ntogether, these results place GPTQ on firm theoretical footing and open the\ndoor to importing decades of progress in lattice algorithms towards the design\nof future quantization algorithms for billion-parameter models.",
        "summary_zh": "将大型语言模型(LLMs)的权重从16位量化到更低位宽是部署大规模transformer到更经济实惠的加速器上的事实标准方法。GPTQ已成为LLM规模一次性后训练量化的标准方法之一。然而，其内部工作机制被描述为一串临时性的代数更新序列，掩盖了任何几何意义或最坏情况保证。在这项工作中，我们表明，当对一个线性层从前向后（从最后一维到第一维）执行时，GPTQ在数学上等同于Babai的最接近平面算法，用于解决由层的输入的Hessian矩阵定义的格上的经典最近向量问题(CVP)。这种等价关系基于一个复杂的数学论证，并有两个分析结果：(i) GPTQ误差传播步骤获得了一个直观的几何解释；(ii) 在无裁剪条件下，GPTQ继承了Babai算法的误差上界。总的来说，这些结果为GPTQ提供了坚实的理论基础，并为导入几十年来格算法的进展以设计未来十亿参数模型的量化算法打开了大门。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "揭示GPTQ量化算法的几何本质，提供理论基础，并指导未来量化算法设计",
        "analysis_time": "2025-08-04T20:04:37.914074"
    },
    {
        "id": "2507.19478",
        "title_en": "MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI   Agents",
        "title_zh": "MMBench-GUI：面向GUI代理的分层多平台评估框架",
        "url": "https://arxiv.org/abs/2507.19478",
        "authors": "Xuehui Wang, Zhenyu Wu, JingJing Xie, Zichen Ding, Bowen Yang, Zehao Li, Zhaoyang Liu, Qingyun Li, Xuan Dong, Zhe Chen, Weiyun Wang, Xiangyu Zhao, Jixuan Chen, Haodong Duan, Tianbao Xie, Chenyu Yang, Shiqian Su, Yue Yu, Yuan Huang, Yiqian Liu, Xiao Zhang, Yanting Zhang, Xiangyu Yue, Weijie Su, Xizhou Zhu, Wei Shen, Jifeng Dai, Wenhai Wang",
        "publish_date": "2025-07-25",
        "summary_en": "We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI\nautomation agents across Windows, macOS, Linux, iOS, Android, and Web\nplatforms. It comprises four levels: GUI Content Understanding, Element\nGrounding, Task Automation, and Task Collaboration, covering essential skills\nfor GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)\nmetric to assess GUI agent execution efficiency in online automation scenarios.\nThrough MMBench-GUI, we identify accurate visual grounding as a critical\ndeterminant of overall task success, emphasizing the substantial benefits of\nmodular frameworks that integrate specialized grounding modules. Furthermore,\nto achieve reliable GUI automation, an agent requires strong task planning and\ncross-platform generalization abilities, with long-context memory, a broad\naction space, and long-term reasoning playing a critical role. More important,\ntask efficiency remains a critically underexplored dimension, and all models\nsuffer from substantial inefficiencies, with excessive redundant steps even\nwhen tasks are ultimately completed. The integration of precise localization,\neffective planning, and early stopping strategies is indispensable to enable\ntruly efficient and scalable GUI automation. Our benchmark code, evaluation\ndata, and running environment will be publicly available at\nhttps://github.com/open-compass/MMBench-GUI.",
        "summary_zh": "我们介绍了MMBench-GUI，一个用于评估跨Windows、macOS、Linux、iOS、Android和Web平台的GUI自动化代理的分层基准测试。它包含四个层级：GUI内容理解、元素定位、任务自动化和任务协作，涵盖了GUI代理的基本技能。此外，我们提出了一种新的效率-质量区域(EQA)指标，用于评估在线自动化场景中GUI代理的执行效率。通过MMBench-GUI，我们发现精确的视觉定位是整体任务成功的关键决定因素，强调了集成专门定位模块的模块化框架的显著优势。此外，要实现可靠的GUI自动化，代理需要强大的任务规划和跨平台泛化能力，其中长上下文记忆、广泛的动作空间和长期推理起着关键作用。更重要的是，任务效率仍然是一个严重未被探索的维度，所有模型都存在显著的低效率问题，即使任务最终完成，也存在大量冗余步骤。精确定位、有效规划和早期停止策略的结合对于实现真正高效且可扩展的GUI自动化是必不可少的。我们的基准测试代码、评估数据和运行环境将在https://github.com/open-compass/MMBench-GUI上公开提供。",
        "github_repo": "https://github.com/open-compass/MMBench-GUI",
        "project_page": "暂无",
        "model_function": "评估跨多平台的GUI自动化代理，包含四个层级的能力测试，并提供效率-质量评估指标。",
        "analysis_time": "2025-08-04T20:04:37.914074"
    },
    {
        "id": "2507.19457",
        "title_en": "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning",
        "title_zh": "GEPA：反思式提示进化可以超越强化学习",
        "url": "https://arxiv.org/abs/2507.19457",
        "authors": "Lakshya A Agrawal, Shangyin Tan, Dilara Soylu, Noah Ziems, Rishi Khare, Krista Opsahl-Ong, Arnav Singhvi, Herumb Shandilya, Michael J Ryan, Meng Jiang, Christopher Potts, Koushik Sen, Alexandros G. Dimakis, Ion Stoica, Dan Klein, Matei Zaharia, Omar Khattab",
        "publish_date": "2025-07-25",
        "summary_en": "Large language models (LLMs) are increasingly adapted to downstream tasks via\nreinforcement learning (RL) methods like Group Relative Policy Optimization\n(GRPO), which often require thousands of rollouts to learn new tasks. We argue\nthat the interpretable nature of language can often provide a much richer\nlearning medium for LLMs, compared with policy gradients derived from sparse,\nscalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt\noptimizer that thoroughly incorporates natural language reflection to learn\nhigh-level rules from trial and error. Given any AI system containing one or\nmore LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool\ncalls, and tool outputs) and reflects on them in natural language to diagnose\nproblems, propose and test prompt updates, and combine complementary lessons\nfrom the Pareto frontier of its own attempts. As a result of GEPA's design, it\ncan often turn even just a few rollouts into a large quality gain. Across four\ntasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up\nto 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,\nMIPROv2, by over 10% across two LLMs, and demonstrates promising results as an\ninference-time search strategy for code optimization.",
        "summary_zh": "大型语言模型(LLMs)正越来越多地通过强化学习(RL)方法(如组相对策略优化(GRPO))适应下游任务，这些方法通常需要数千次 rollout 才能学习新任务。我们认为，与从稀疏、标量奖励中导出的策略梯度相比，语言的可解释性往往能为LLMs提供更丰富的学习媒介。为验证这一点，我们引入了GEPA(Genetic-Pareto)，一种提示优化器，它充分融入自然语言反思，通过试错学习高级规则。对于任何包含一个或多个LLM提示的AI系统，GEPA会对系统级别的轨迹(如推理、工具调用和工具输出)进行采样，并用自然语言对其进行反思，以诊断问题、提出和测试提示更新，并结合自身尝试的帕累托前沿中的互补经验。由于GEPA的设计，它通常可以将少数几次 rollout 转化为显著的性能提升。在四项任务中，GEPA平均比GRPO高出10%，最高高出20%，同时使用的 rollout 次数最多减少35倍。GEPA还领先于最先进的提示优化器MIPROv2，在两个LLM上表现超过10%，并展现出作为代码优化推理时搜索策略的 promising 结果。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "GEPA是一种提示优化器，通过自然语言反思和帕累托前沿分析，以极少的rollout次数高效提升大型语言模型性能。",
        "analysis_time": "2025-08-04T20:04:38.131556"
    },
    {
        "id": "2507.16075",
        "title_en": "Deep Researcher with Test-Time Diffusion",
        "title_zh": "基于测试时扩散的深度研究代理",
        "url": "https://arxiv.org/abs/2507.16075",
        "authors": "Rujun Han, Yanfei Chen, Zoey CuiZhu, Lesly Miculicich, Guan Sun, Yuanjun Bi, Weiming Wen, Hui Wan, Chunfeng Wen, Solène Maître, George Lee, Vishy Tirumalashetty, Emily Xue, Zizhao Zhang, Salem Haykal, Burak Gokturk, Tomas Pfister, Chen-Yu Lee",
        "publish_date": "2025-07-21",
        "summary_en": "Deep research agents, powered by Large Language Models (LLMs), are rapidly\nadvancing; yet, their performance often plateaus when generating complex,\nlong-form research reports using generic test-time scaling algorithms. Drawing\ninspiration from the iterative nature of human research, which involves cycles\nof searching, reasoning, and revision, we propose the Test-Time Diffusion Deep\nResearcher (TTD-DR). This novel framework conceptualizes research report\ngeneration as a diffusion process. TTD-DR initiates this process with a\npreliminary draft, an updatable skeleton that serves as an evolving foundation\nto guide the research direction. The draft is then iteratively refined through\na \"denoising\" process, which is dynamically informed by a retrieval mechanism\nthat incorporates external information at each step. The core process is\nfurther enhanced by a self-evolutionary algorithm applied to each component of\nthe agentic workflow, ensuring the generation of high-quality context for the\ndiffusion process. This draft-centric design makes the report writing process\nmore timely and coherent while reducing information loss during the iterative\nsearch process. We demonstrate that our TTD-DR achieves state-of-the-art\nresults on a wide array of benchmarks that require intensive search and\nmulti-hop reasoning, significantly outperforming existing deep research agents.",
        "summary_zh": "由大型语言模型(LLM)驱动的深度研究代理正在快速发展；然而，当使用通用的测试时扩展算法生成复杂的长篇研究报告时，它们的性能往往会达到瓶颈。受人类研究迭代性质的启发，人类研究涉及搜索、推理和修订的循环，我们提出了测试时扩散深度研究代理(TTD-DR)。这个新框架将研究报告的生成概念化为一个扩散过程。TTD-DR通过初步草稿启动这一过程，这是一个可更新的骨架，作为不断发展的基础来指导研究方向。然后，草稿通过一个\"去噪\"过程进行迭代细化，该过程由一个检索机制动态提供信息，该机制在每个步骤都融入外部信息。核心过程通过应用于代理工作流每个组件的自进化算法得到进一步增强，确保为扩散过程生成高质量上下文。这种以草稿为中心的设计使报告写作过程更加及时和连贯，同时减少了迭代搜索过程中的信息损失。我们证明了我们的TTD-DR在需要密集搜索和多跳推理的各种基准测试上取得了最先进的结果，显著优于现有的深度研究代理。",
        "github_repo": "https://github.com/codelion/optillm/tree/main/optillm/plugins/deep_research",
        "project_page": "暂无",
        "model_function": "通过测试时扩散框架生成高质量研究报告，结合检索机制和自进化算法提升研究代理性能。",
        "analysis_time": "2025-08-04T20:04:38.706384"
    },
    {
        "id": "2507.16534",
        "title_en": "Frontier AI Risk Management Framework in Practice: A Risk Analysis   Technical Report",
        "title_zh": "前沿人工智能风险管理框架实践：风险分析技术报告",
        "url": "https://arxiv.org/abs/2507.16534",
        "authors": "Shanghai AI Lab, Xiaoyang Chen, Yunhao Chen, Zeren Chen, Zhiyun Chen, Hanyun Cui, Yawen Duan, Jiaxuan Guo, Qi Guo, Xuhao Hu, Hong Huang, Lige Huang, Chunxiao Li, Juncheng Li, Qihao Lin, Dongrui Liu, Xinmin Liu, Zicheng Liu, Chaochao Lu, Xiaoya Lu, Jingjing Qu, Qibing Ren, Jing Shao, Jingwei Shi, Jingwei Sun, Peng Wang, Weibing Wang, Jia Xu, Lewen Yan, Xiao Yu, Yi Yu, Boxuan Zhang, Jie Zhang, Weichen Zhang, Zhijie Zheng, Tianyi Zhou, Bowen Zhou",
        "publish_date": "2025-07-22",
        "summary_en": "To understand and identify the unprecedented risks posed by rapidly advancing\nartificial intelligence (AI) models, this report presents a comprehensive\nassessment of their frontier risks. Drawing on the E-T-C analysis (deployment\nenvironment, threat source, enabling capability) from the Frontier AI Risk\nManagement Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks\nin seven areas: cyber offense, biological and chemical risks, persuasion and\nmanipulation, uncontrolled autonomous AI R\\&D, strategic deception and\nscheming, self-replication, and collusion. Guided by the \"AI-45^circ Law,\"\nwe evaluate these risks using \"red lines\" (intolerable thresholds) and \"yellow\nlines\" (early warning indicators) to define risk zones: green (manageable risk\nfor routine deployment and continuous monitoring), yellow (requiring\nstrengthened mitigations and controlled deployment), and red (necessitating\nsuspension of development and/or deployment). Experimental results show that\nall recent frontier AI models reside in green and yellow zones, without\ncrossing red lines. Specifically, no evaluated models cross the yellow line for\ncyber offense or uncontrolled AI R\\&D risks. For self-replication, and\nstrategic deception and scheming, most models remain in the green zone, except\nfor certain reasoning models in the yellow zone. In persuasion and\nmanipulation, most models are in the yellow zone due to their effective\ninfluence on humans. For biological and chemical risks, we are unable to rule\nout the possibility of most models residing in the yellow zone, although\ndetailed threat modeling and in-depth assessment are required to make further\nclaims. This work reflects our current understanding of AI frontier risks and\nurges collective action to mitigate these challenges.",
        "summary_zh": "为了理解和识别快速发展的人工智能(AI)模型带来的前所未有的风险，本报告对其前沿风险进行了全面评估。借鉴前沿人工智能风险管理框架(v1.0)(SafeWork-F1-Framework)中的E-T-C分析(部署环境、威胁源、赋能能力)，我们确定了七个关键风险领域：网络攻击、生物和化学风险、说服和操纵、不受控制的自主AI研发、战略欺骗和阴谋、自我复制和共谋。在\"AI-45°法则\"的指导下，我们使用\"红线\"(不可接受的阈值)和\"黄线\"(早期预警指标)来评估这些风险，从而定义风险区域：绿色(常规部署和持续监控的可管理风险)、黄色(需要加强缓解措施和受控部署)和红色(需要暂停开发和/或部署)。实验结果表明，所有最近的前沿AI模型都位于绿色和黄色区域，没有跨越红线。具体而言，没有评估的模型跨越网络攻击或不受控制的AI研发风险的黄线。对于自我复制以及战略欺骗和阴谋，大多数模型保持在绿色区域，除了某些推理模型处于黄色区域。在说服和操纵方面，由于模型能有效影响人类，大多数模型处于黄色区域。对于生物和化学风险，我们无法排除大多数模型可能处于黄色区域的可能，尽管需要详细的威胁建模和深入评估才能做出进一步的主张。这项工作反映了我们对AI前沿风险的当前理解，并呼吁集体行动来缓解这些挑战。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "评估前沿AI模型风险，提供风险分类和应对建议，促进AI安全发展。",
        "analysis_time": "2025-08-04T20:04:46.974347"
    },
    {
        "id": "2507.17596",
        "title_en": "PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving",
        "title_zh": "PRIX：从原始像素学习规划以实现端到端自动驾驶",
        "url": "https://arxiv.org/abs/2507.17596",
        "authors": "Maciej K. Wozniak, Lianhang Liu, Yixi Cai, Patric Jensfelt",
        "publish_date": "2025-07-23",
        "summary_en": "While end-to-end autonomous driving models show promising results, their\npractical deployment is often hindered by large model sizes, a reliance on\nexpensive LiDAR sensors and computationally intensive BEV feature\nrepresentations. This limits their scalability, especially for mass-market\nvehicles equipped only with cameras. To address these challenges, we propose\nPRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving\narchitecture operates using only camera data, without explicit BEV\nrepresentation and forgoing the need for LiDAR. PRIX leverages a visual feature\nextractor coupled with a generative planning head to predict safe trajectories\nfrom raw pixel inputs directly. A core component of our architecture is the\nContext-aware Recalibration Transformer (CaRT), a novel module designed to\neffectively enhance multi-level visual features for more robust planning. We\ndemonstrate through comprehensive experiments that PRIX achieves\nstate-of-the-art performance on the NavSim and nuScenes benchmarks, matching\nthe capabilities of larger, multimodal diffusion planners while being\nsignificantly more efficient in terms of inference speed and model size, making\nit a practical solution for real-world deployment. Our work is open-source and\nthe code will be at https://maxiuw.github.io/prix.",
        "summary_zh": "尽管端到端自动驾驶模型显示出 promising 的结果，但它们的实际部署常常受到大型模型尺寸、对昂贵LiDAR传感器的依赖以及计算密集型BEV特征表示的阻碍。这限制了它们的可扩展性，特别是对于仅配备摄像头的量产车辆。为应对这些挑战，我们提出了PRIX（从原始像素规划）。我们新颖且高效的端到端驾驶架构仅使用摄像头数据运行，没有显式的BEV表示，也不需要LiDAR。PRIX利用视觉特征提取器与生成式规划头相结合，直接从原始像素输入预测安全轨迹。我们架构的核心组件是上下文感知重校准Transformer（CaRT），这是一个新颖的模块，旨在有效增强多级视觉特征以实现更稳健的规划。我们通过全面实验证明，PRIX在NavSim和nuScenes基准测试上达到了最先进的性能，匹配了更大的多模态扩散规划器的能力，同时在推理速度和模型大小方面显著更高效，使其成为实际部署的实用解决方案。我们的工作是开源的，代码将在https://maxiuw.github.io/prix上提供。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "仅使用摄像头数据的端到端自动驾驶规划架构，直接从原始像素预测安全轨迹，实现高效实用的自动驾驶解决方案。",
        "analysis_time": "2025-08-04T20:04:48.005291"
    },
    {
        "id": "2507.18392",
        "title_en": "CLEAR: Error Analysis via LLM-as-a-Judge Made Easy",
        "title_zh": "CLEAR：通过LLM作为评判者简化错误分析",
        "url": "https://arxiv.org/abs/2507.18392",
        "authors": "Asaf Yehudai, Lilach Eden, Yotam Perlitz, Roy Bar-Haim, Michal Shmueli-Scheuer",
        "publish_date": "2025-07-24",
        "summary_en": "The evaluation of Large Language Models (LLMs) increasingly relies on other\nLLMs acting as judges. However, current evaluation paradigms typically yield a\nsingle score or ranking, answering which model is better but not why. While\nessential for benchmarking, these top-level scores obscure the specific,\nactionable reasons behind a model's performance. To bridge this gap, we\nintroduce CLEAR, an interactive, open-source package for LLM-based error\nanalysis. CLEAR first generates per-instance textual feedback, then it creates\na set of system-level error issues, and quantifies the prevalence of each\nidentified issue. Our package also provides users with an interactive dashboard\nthat allows for a comprehensive error analysis through aggregate\nvisualizations, applies interactive filters to isolate specific issues or score\nranges, and drills down to the individual instances that exemplify a particular\nbehavioral pattern. We demonstrate CLEAR analysis for RAG and Math benchmarks,\nand showcase its utility through a user case study.",
        "summary_zh": "大型语言模型(LLMs)的评估越来越依赖于其他LLM作为评判者。然而，当前的评估范式通常只产生单一分数或排名，回答哪个模型更好但不回答为什么。虽然这些顶级分数对基准测试至关重要，但它们掩盖了模型性能背后的具体、可操作的原因。为了弥合这一差距，我们介绍了CLEAR，这是一个用于基于LLM的错误分析的交互式开源软件包。CLEAR首先生成每个实例的文本反馈，然后创建一组系统级错误问题，并量化每个已识别问题的普遍性。我们的软件包还为用户提供了一个交互式仪表板，允许通过聚合可视化进行全面错误分析，应用交互式过滤器来隔离特定问题或分数范围，并深入到展示特定行为模式的个体实例。我们展示了CLEAR在RAG和数学基准测试中的分析，并通过用户案例研究展示了其效用。",
        "github_repo": "https://github.com/IBM/CLEAR",
        "project_page": "暂无",
        "model_function": "基于LLM的交互式错误分析工具，提供详细的错误原因可视化和量化分析。",
        "analysis_time": "2025-08-04T20:04:48.826212"
    },
    {
        "id": "2507.10510",
        "title_en": "Chat with AI: The Surprising Turn of Real-time Video Communication from   Human to AI",
        "title_zh": "与AI聊天：实时视频通信从人到AI的惊人转变",
        "url": "https://arxiv.org/abs/2507.10510",
        "authors": "Jiangkai Wu, Zhiyuan Ren, Liming Liu, Xinggong Zhang",
        "publish_date": "2025-07-14",
        "summary_en": "AI Video Chat emerges as a new paradigm for Real-time Communication (RTC),\nwhere one peer is not a human, but a Multimodal Large Language Model (MLLM).\nThis makes interaction between humans and AI more intuitive, as if chatting\nface-to-face with a real person. However, this poses significant challenges to\nlatency, because the MLLM inference takes up most of the response time, leaving\nvery little time for video streaming. Due to network uncertainty and\ninstability, transmission latency becomes a critical bottleneck preventing AI\nfrom being like a real person. To address this, we propose Artic, an\nAI-oriented Real-time Communication framework, exploring the network\nrequirement shift from \"humans watching video\" to \"AI understanding video\". To\nreduce bitrate dramatically while maintaining MLLM accuracy, we propose\nContext-Aware Video Streaming that recognizes the importance of each video\nregion for chat and allocates bitrate almost exclusively to chat-important\nregions. To avoid packet retransmission, we propose Loss-Resilient Adaptive\nFrame Rate that leverages previous frames to substitute for lost/delayed frames\nwhile avoiding bitrate waste. To evaluate the impact of video streaming quality\non MLLM accuracy, we build the first benchmark, named Degraded Video\nUnderstanding Benchmark (DeViBench). Finally, we discuss some open questions\nand ongoing solutions for AI Video Chat.",
        "summary_zh": "AI视频聊天 emerges as a new paradigm for Real-time Communication (RTC)，其中一方不是人类，而是多模态大语言模型(MLLM)。这使得人类与AI之间的交互更加直观，就像与真人面对面聊天一样。然而，这对延迟提出了重大挑战，因为MLLM推理占据了大部分响应时间，留给视频流传输的时间非常少。由于网络的不确定性和不稳定性，传输延迟成为阻碍AI像真人一样互动的关键瓶颈。为解决这一问题，我们提出了Artic，一个面向AI的实时通信框架，探索了网络需求从\"人类观看视频\"到\"AI理解视频\"的转变。为显著降低比特率同时保持MLLM准确性，我们提出了上下文感知的视频流传输，它识别聊天中每个视频区域的重要性，并将比特率几乎完全分配给聊天重要的区域。为避免数据包重传，我们提出了具有容错性的自适应帧率，它利用前一帧替代丢失/延迟的帧，同时避免比特率浪费。为评估视频流质量对MLLM准确性的影响，我们构建了第一个基准测试，名为降级视频理解基准。最后，我们讨论了AI视频聊天的一些开放问题和正在进行的解决方案。",
        "github_repo": "暂无",
        "project_page": "暂无",
        "model_function": "提出Artic框架，通过上下文感知视频流和容错自适应帧率技术，实现高效的人与AI实时视频交互。",
        "analysis_time": "2025-08-04T20:04:56.241695"
    },
    {
        "id": "2507.17957",
        "title_en": "AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic   Segmentation",
        "title_zh": "AFRDA：用于领域自适应语义分割的注意力特征精炼",
        "url": "https://arxiv.org/abs/2507.17957",
        "authors": "Md. Al-Masrur Khan, Durgakant Pushp, Lantao Liu",
        "publish_date": "2025-07-23",
        "summary_en": "In Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS), a model is\ntrained on labeled source domain data (e.g., synthetic images) and adapted to\nan unlabeled target domain (e.g., real-world images) without access to target\nannotations. Existing UDA-SS methods often struggle to balance fine-grained\nlocal details with global contextual information, leading to segmentation\nerrors in complex regions. To address this, we introduce the Adaptive Feature\nRefinement (AFR) module, which enhances segmentation accuracy by refining\nhighresolution features using semantic priors from low-resolution logits. AFR\nalso integrates high-frequency components, which capture fine-grained\nstructures and provide crucial boundary information, improving object\ndelineation. Additionally, AFR adaptively balances local and global information\nthrough uncertaintydriven attention, reducing misclassifications. Its\nlightweight design allows seamless integration into HRDA-based UDA methods,\nleading to state-of-the-art segmentation performance. Our approach improves\nexisting UDA-SS methods by 1.05% mIoU on GTA V --> Cityscapes and 1.04% mIoU on\nSynthia-->Cityscapes. The implementation of our framework is available at:\nhttps://github.com/Masrur02/AFRDA",
        "summary_zh": "在无监督领域自适应语义分割(UDA-SS)中，模型在有标签的源域数据(例如合成图像)上进行训练，并在没有目标域标注的情况下适应无标签的目标域(例如真实世界图像)。现有的UDA-SS方法往往难以平衡细粒度的局部细节和全局上下文信息，导致复杂区域出现分割错误。为解决这一问题，我们引入了自适应特征精炼(AFR)模块，该模块通过利用低分辨率logits的语义先验来精炼高分辨率特征，从而提高分割准确性。AFR还集成了高频分量，这些分量能够捕获细粒度结构并提供重要的边界信息，改善对象轮廓划分。此外，AFR通过不确定性驱动的注意力机制自适应地平衡局部和全局信息，减少错误分类。其轻量级设计允许无缝集成到基于HRDA的UDA方法中，实现最先进的分割性能。我们的方法在GTA V --> Cityscapes上将现有的UDA-SS方法提高了1.05% mIoU，在Synthia-->Cityscapes上提高了1.04% mIoU。我们框架的实现可在以下网址获取：https://github.com/Masrur02/AFRDA",
        "github_repo": "https://github.com/Masrur02/AFRDA",
        "project_page": "暂无",
        "model_function": "通过注意力特征精炼模块提升领域自适应语义分割性能，平衡局部细节与全局信息，改善复杂区域的分割准确性。",
        "analysis_time": "2025-08-04T20:04:58.340233"
    },
    {
        "id": "2507.18742",
        "title_en": "Specification Self-Correction: Mitigating In-Context Reward Hacking   Through Test-Time Refinement",
        "title_zh": "规范自我纠正：通过测试时优化减轻上下文奖励黑客攻击",
        "url": "https://arxiv.org/abs/2507.18742",
        "authors": "Víctor Gallego",
        "publish_date": "2025-07-24",
        "summary_en": "Language models (LMs) are susceptible to in-context reward hacking, where\nthey exploit flaws in tainted or faulty written specifications or rubrics to\nachieve high scores without fulfilling the user's true intent. We introduce\nSpecification Self-Correction (SSC), a novel, test-time framework that enables\nan LM to identify and correct flaws within its own guiding specification. SSC\nemploys a multi-step inference process where the model first generates a\nresponse based on a potentially tainted specification, critiques its output,\nand then revises the specification itself to remove the exploitable loophole. A\nfinal, more robust response is then generated using this self-corrected\nspecification. Across experiments spanning creative writing and agentic coding\ntasks with several LMs, we demonstrate that while models initially game tainted\nspecifications in 50-70\\% of cases, the SSC process reduces this vulnerability\nby over 90\\%. This dynamic repair occurs at inference time, requires no weight\nmodification, and leads to more robustly aligned model behavior. Code at\nhttps://github.com/vicgalle/specification-self-correction .",
        "summary_zh": "语言模型(LMs)容易受到上下文奖励黑客攻击的威胁，其中模型利用被污染或有缺陷的书面规范或评分标准中的漏洞，在不满足用户真实意图的情况下获得高分。我们引入规范自我纠正(SSC)，这是一种新颖的测试时框架，使语言模型能够识别并纠正其自身指导规范中的缺陷。SSC采用多步推理过程，模型首先根据可能被污染的规范生成响应，然后对其输出进行批判，接着修改规范本身以消除可利用的漏洞。然后，使用这种自我纠正后的规范生成最终更稳健的响应。在涵盖创意写作和代理编码任务的多个语言模型的实验中，我们证明虽然模型最初在50-70%的情况下利用被污染的规范进行欺骗，但SSC过程将这种脆弱性降低了90%以上。这种动态修复发生在推理时，不需要修改权重，并导致更稳健对齐的模型行为。代码可在 https://github.com/vicgalle/specification-self-correction 获取。",
        "github_repo": "https://github.com/vicgalle/specification-self-correction",
        "project_page": "暂无",
        "model_function": "规范自我纠正框架，使模型在推理时识别并纠正自身规范缺陷，减轻奖励黑客攻击，提高模型稳健性。",
        "analysis_time": "2025-08-04T20:05:00.569065"
    }
]